{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e07e49f0-ce3e-4689-9ac1-2da282b1b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Levenshtein import ratio as levenshtein_ratio\n",
    "import hdbscan\n",
    "from tqdm import tqdm\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7362465-2b87-4f44-bc45-8fbc0810db40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = r\"d:/Users/sinshi/Documents/Zothers/IndividualCustomer.xlsx\"\n",
    "df = pd.read_excel(file_path, usecols=['NameList', 'DateLst', 'IDLst'])\n",
    "df.dropna(subset=['NameList'], inplace=True)\n",
    "df['group_id'] = df.index\n",
    "\n",
    "# Save original full alias list before exploding\n",
    "df['NameList_original'] = df['NameList']\n",
    "\n",
    "# Expand aliases and clean individual names\n",
    "df = df.assign(alias_name=df['NameList'].str.split(',')).explode('alias_name')\n",
    "df['clean_name'] = df['alias_name'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True).str.strip()\n",
    "\n",
    "df.drop_duplicates(subset=['group_id', 'clean_name'], inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Restore NameList column\n",
    "df.rename(columns={'NameList_original': 'NameList'}, inplace=True)\n",
    "csv_file_path = \"D:/project-folder/model/metadata.csv\"\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "#df.to_csv('D:/project-folder/model', index=False)\n",
    "#df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a05499d1-5902-4dc7-a40a-84ee9eb2160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 134/134 [00:57<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "batch_size = 64\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    batch = df['clean_name'].iloc[i:i+batch_size].tolist()\n",
    "    emb = model.encode(batch, show_progress_bar=False)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.vstack(embeddings).astype('float32')\n",
    "filepath = \"D:/project-folder/model/name_embeddings.npy\"\n",
    "np.save(filepath, embeddings)\n",
    "filepath_2 = \"D:/project-folder/model/sentence_model\"\n",
    "model.save(filepath_2)\n",
    "#index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "#index.add(embeddings)\n",
    "#filepath_2\n",
    "#faiss.write_index(index, \"D:/project-folder/model/faiss.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b1bbf5d-00e3-41e1-8ef2-7f695588893c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NameList</th>\n",
       "      <th>DateLst</th>\n",
       "      <th>IDLst</th>\n",
       "      <th>group_id</th>\n",
       "      <th>NameList</th>\n",
       "      <th>alias_name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chol Ung Nam,Chol-Ung Nam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Chol Ung Nam,Chol-Ung Nam</td>\n",
       "      <td>Chol Ung Nam</td>\n",
       "      <td>chol ung nam</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chol Ung Nam,Chol-Ung Nam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Chol Ung Nam,Chol-Ung Nam</td>\n",
       "      <td>Chol-Ung Nam</td>\n",
       "      <td>cholung nam</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...</td>\n",
       "      <td>0/0/1964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...</td>\n",
       "      <td>Apollinaire Hakizimana</td>\n",
       "      <td>apollinaire hakizimana</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...</td>\n",
       "      <td>0/0/1964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...</td>\n",
       "      <td>Amikwe Lepic</td>\n",
       "      <td>amikwe lepic</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...</td>\n",
       "      <td>0/0/1964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...</td>\n",
       "      <td>Poete</td>\n",
       "      <td>poete</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            NameList   DateLst IDLst  \\\n",
       "0                          Chol Ung Nam,Chol-Ung Nam       NaN   NaN   \n",
       "1                          Chol Ung Nam,Chol-Ung Nam       NaN   NaN   \n",
       "2  Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...  0/0/1964   NaN   \n",
       "3  Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...  0/0/1964   NaN   \n",
       "4  Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...  0/0/1964   NaN   \n",
       "\n",
       "   group_id                                           NameList  \\\n",
       "0         0                          Chol Ung Nam,Chol-Ung Nam   \n",
       "1         0                          Chol Ung Nam,Chol-Ung Nam   \n",
       "2         1  Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...   \n",
       "3         1  Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...   \n",
       "4         1  Apollinaire Hakizimana,Amikwe Lepic,Poete,Le P...   \n",
       "\n",
       "               alias_name              clean_name  cluster_id  \n",
       "0            Chol Ung Nam            chol ung nam          -1  \n",
       "1            Chol-Ung Nam             cholung nam          -1  \n",
       "2  Apollinaire Hakizimana  apollinaire hakizimana          -1  \n",
       "3            Amikwe Lepic            amikwe lepic          -1  \n",
       "4                   Poete                   poete          -1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, metric='euclidean')\n",
    "df['cluster_id'] = clusterer.fit_predict(embeddings)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6520a67-362d-4c44-8509-0dd94cbc22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_final_match(row, similarity_threshold=0.75):\n",
    "    if row['cosine_sim'] >= similarity_threshold and (row['dob_match'] or row['id_match']):\n",
    "        return \"Strong Match\"\n",
    "    elif row['cosine_sim'] >= similarity_threshold:\n",
    "        return \"Probable Match\"\n",
    "    else:\n",
    "        return \"Weak or No Match\"\n",
    "\n",
    "def find_similar_names(query_name, input_dob=None, input_id=None, top_k=5, threshold=0.7):\n",
    "    name_clean = re.sub(r\"[^\\w\\s]\", \"\", query_name.lower()).strip()\n",
    "    query_vec = model.encode([name_clean]).astype(\"float32\")\n",
    "    \n",
    "    # Calculate cosine similarity between the query and all stored embeddings\n",
    "    sims = cosine_similarity(query_vec, embeddings)[0]\n",
    "    df['cosine_sim'] = sims  # Add cosine similarity to DataFrame\n",
    "\n",
    "    # Get top_k matches based on cosine similarity\n",
    "    top_matches = df.nlargest(top_k, 'cosine_sim').copy()\n",
    "\n",
    "    # Rule-based filters: Match by Date of Birth (dob) and ID\n",
    "    top_matches['dob_match'] = top_matches['DateLst'].astype(str) == str(input_dob) if input_dob else False\n",
    "    top_matches['id_match'] = top_matches['IDLst'].astype(str) == str(input_id) if input_id else False\n",
    "\n",
    "    # Filter out results that do not meet the cosine similarity threshold\n",
    "    filtered = top_matches[top_matches['cosine_sim'] >= threshold]\n",
    "\n",
    "    if filtered.empty:\n",
    "        return \"No match found\"\n",
    "\n",
    "    # Return relevant columns as a dictionary of top matches (including NameList, alias_name, etc.)\n",
    "    return filtered[['NameList', 'alias_name', 'DateLst', 'IDLst', 'cosine_sim', 'dob_match', 'id_match']].to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3eab47ba-879e-41e6-a2c2-95df8fff468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'NameList': 'Jamil Mukulu,Sheikh Jamil Mukulu,Steven Alirabaki,Abdullah Junju,Alilabaki Kyagulanyi,David Kyagulanyi,Nicolas Luumu,Hussein Muhammad,Musezi Talengelanimiro,Mzee Tutu,Talengelanimiro,Abdullah Junjuaka,Jamil Alirabaki,Mazengo David Amos,Lwanga Thomas Musisi,Nicholas Lumu,Philipp Nyanzi,Abdullah Jjungu,Petanguli Kalemire,Denis Kityo Musoke,David Amos Mazengo,Julius Elius Mashauri,Kyagulanyi Alibaki,Stephen Kyagulanyi,Jamil Ali Libaki,Ismael Rijab,Talengelanimiro Musezi,Kityo Denis Musoke,Jamil Alkyagulanyi,Mukongozzi Sengooba Kyakonye,Kalamire Patanguli,Moses Sngoba,Abdallah Jumju,Ismael Rajabu,Julius Elius Mashairi,Nyanzi Yafeesi Phillip,David Alilabaki,Jamil Makulu,Lumu Nicholas,Sheik Jamil Mukulu Kyagulanyi,Julius Nicholas,Patanguli Kalamire,Jimmy Makulu,Jjungu Abdallah,Julius Elius,Professor Musharaf,Yafesi,Musharaf', 'alias_name': 'Hussein Muhammad', 'DateLst': datetime.datetime(1964, 4, 17, 0, 0), 'IDLst': nan, 'cosine_sim': 0.8152835369110107, 'dob_match': False, 'id_match': False}, {'NameList': 'Ali Akbar Ahmadian,Ali Akbar Ahmadiyan,Ali Akbar Ahmedian,Ali Akbar Ahmedien,Ali Akbar Ahmadian Babaki,Ali Ahmadian,Ali Ahmadiyan', 'alias_name': 'Ali Akbar Ahmedien', 'DateLst': '0/0/1961', 'IDLst': nan, 'cosine_sim': 0.8068321347236633, 'dob_match': False, 'id_match': False}, {'NameList': 'Ali Akbar Ahmadian,Ali Akbar Ahmadiyan,Ali Akbar Ahmedian,Ali Akbar Ahmedien,Ali Akbar Ahmadian Babaki,Ali Ahmadian,Ali Ahmadiyan', 'alias_name': 'Ali Akbar Ahmadian', 'DateLst': '0/0/1961', 'IDLst': nan, 'cosine_sim': 0.8033708333969116, 'dob_match': False, 'id_match': False}, {'NameList': \"Sayyid Ali Akbar Tabatabaei,Sayed Akbar Tahmaesebi,Ali Akbar Tabatabaei,Sayyed Ali Tabatabaee,Seyed Akbar Tabatabaei,Syed Tabatabaei,Akbar Tahmasebi,Seyed Tahmasebi,Ali Akbar Tahmaesebi,Ali Akber Tabatabaei,Ali Akber Tahmaesebi,Syed Akber Tahmaesebi,Ali Akber Tabatabae,Ali Akber Tahmaesbebi,Ali Akbar Tatabaei,Ali Akbar Tabatabaie,Sayyid Ali Tabatabaei,Seyed Akbar Tahmaesebi,Syed Akbar Tahmaesebi,Sayyed Ali Tabataba'ie,Seyed Akbar Tabataba'i\", 'alias_name': 'Ali Akbar Tahmaesebi', 'DateLst': '0/0/1967', 'IDLst': 6620505, 'cosine_sim': 0.7901567220687866, 'dob_match': False, 'id_match': False}, {'NameList': 'Dinno Amor Rosalejos Pareja,Johnny Pareja,Khalil Pareja,Khalil Pareja Aminah,Dinno Rosalejos Pareja,Dino Amor Rosalejo Pareja,Khalil Rahman R Pareja,Dino Amor Pareja,Abu Jihad,Mohammad,Akmad,Mighty,Rash,Akmal,Jeny,Al-Luzoni,Akhmad,Kahlil Pareja,Dino Amor Rosalejos-Pareja', 'alias_name': 'Mohammad', 'DateLst': datetime.datetime(1981, 7, 19, 0, 0), 'IDLst': nan, 'cosine_sim': 0.7894397974014282, 'dob_match': False, 'id_match': False}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinshi\\AppData\\Local\\Temp\\ipykernel_5212\\1128633702.py:31: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  return filtered[['NameList', 'alias_name', 'DateLst', 'IDLst', 'cosine_sim', 'dob_match', 'id_match']].to_dict(orient='records')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"sinshi\" with any input name and optional DOB/ID\n",
    "results = find_similar_names(\"mohammad akbar\", input_dob=None, input_id=None)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537b154-17ff-4ce8-a0bf-aa144a33f2c8",
   "metadata": {},
   "source": [
    "\"\"\"pairs = []\n",
    "labels = []\n",
    "\n",
    "# Positive pairs: same cluster\n",
    "for cluster_id in df['cluster_id'].unique():\n",
    "    cluster_members = df[df['cluster_id'] == cluster_id]\n",
    "    if cluster_id == -1 or len(cluster_members) < 2:\n",
    "        continue\n",
    "    idxs = cluster_members.index.tolist()\n",
    "    for i in range(len(idxs)):\n",
    "        for j in range(i+1, len(idxs)):\n",
    "            pairs.append((idxs[i], idxs[j]))\n",
    "            labels.append(1)\n",
    "\n",
    "# Negative pairs: different clusters\n",
    "negative_pairs_needed = len(pairs)\n",
    "all_indices = df.index.tolist()\n",
    "\n",
    "import random\n",
    "while len(labels) < 2 * negative_pairs_needed:\n",
    "    i, j = random.sample(all_indices, 2)\n",
    "    if df.at[i, 'cluster_id'] != df.at[j, 'cluster_id']:\n",
    "        pairs.append((i, j))\n",
    "        labels.append(0)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65e9bbc1-a2dc-4e57-b298-a7216b966289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def extract_features(idx1, idx2):\\n    name1 = df.loc[idx1, 'clean_name']\\n    name2 = df.loc[idx2, 'clean_name']\\n    embedding1 = embeddings[idx1]\\n    embedding2 = embeddings[idx2]\\n    \\n    cos_sim = cosine_similarity([embedding1], [embedding2])[0][0]\\n    lev_sim = levenshtein_ratio(name1, name2)\\n    dob_match = float(df.loc[idx1, 'DateLst'] == df.loc[idx2, 'DateLst'])\\n    id_match = float(df.loc[idx1, 'IDLst'] == df.loc[idx2, 'IDLst'])\\n    \\n    return [cos_sim, lev_sim, dob_match, id_match]\\n\\nX = np.array([extract_features(i, j) for i, j in pairs])\\ny = np.array(labels)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def extract_features(idx1, idx2):\n",
    "    name1 = df.loc[idx1, 'clean_name']\n",
    "    name2 = df.loc[idx2, 'clean_name']\n",
    "    embedding1 = embeddings[idx1]\n",
    "    embedding2 = embeddings[idx2]\n",
    "    \n",
    "    cos_sim = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    lev_sim = levenshtein_ratio(name1, name2)\n",
    "    dob_match = float(df.loc[idx1, 'DateLst'] == df.loc[idx2, 'DateLst'])\n",
    "    id_match = float(df.loc[idx1, 'IDLst'] == df.loc[idx2, 'IDLst'])\n",
    "    \n",
    "    return [cos_sim, lev_sim, dob_match, id_match]\n",
    "\n",
    "X = np.array([extract_features(i, j) for i, j in pairs])\n",
    "y = np.array(labels)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e0f0f1-0c4e-436d-bdbf-87ceebb21ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\\nclf.fit(X_train, y_train)\\n\\ny_pred = clf.predict(X_test)\\nprint(classification_report(y_test, y_pred))'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5326843b-b8bb-4086-8a41-c3a7ed3b2d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\sinshi\\AppData\\Local\\Temp\\ipykernel_5212\\991570741.py:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  \"\"\"def hybrid_name_matcher(input_name, input_dob=None, input_id=None, top_k=5, ml_threshold=0.5):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def hybrid_name_matcher(input_name, input_dob=None, input_id=None, top_k=5, ml_threshold=0.5):\\n    name_clean = re.sub(r\"[^\\\\w\\\\s]\", \"\", input_name.lower()).strip()\\n    query_vec = model.encode([name_clean]).astype(\\'float32\\')\\n\\n    cos_sims = cosine_similarity(query_vec, embeddings)[0]\\n    best_index = np.argmax(cos_sims)\\n    cluster_id = df.loc[best_index, \\'cluster_id\\']\\n\\n    if cluster_id == -1:\\n        top_indices = np.argsort(cos_sims)[::-1][:top_k*3]\\n        candidates = df.loc[top_indices].copy()\\n        candidate_embeddings = embeddings[top_indices]\\n        candidate_cos_sims = cos_sims[top_indices]\\n    else:\\n        candidates = df[df[\\'cluster_id\\'] == cluster_id].copy()\\n        candidate_embeddings = embeddings[candidates.index]\\n        candidate_cos_sims = cosine_similarity(query_vec, candidate_embeddings)[0]\\n\\n    candidates = candidates.assign(cos_sim=candidate_cos_sims)\\n    candidates[\\'levenshtein\\'] = candidates[\\'clean_name\\'].apply(lambda x: levenshtein_ratio(name_clean, x))\\n    candidates[\\'dob_match\\'] = candidates[\\'DateLst\\'].astype(str) == str(input_dob) if input_dob else False\\n    candidates[\\'id_match\\'] = candidates[\\'IDLst\\'].astype(str) == str(input_id) if input_id else False\\n\\n    features = candidates[[\\'cos_sim\\', \\'levenshtein\\', \\'dob_match\\', \\'id_match\\']].astype(float)\\n    candidates[\\'match_prob\\'] = clf.predict_proba(features)[:, 1]\\n\\n    final_matches = candidates[candidates[\\'match_prob\\'] >= ml_threshold].sort_values(by=\\'match_prob\\', ascending=False)\\n\\n    if final_matches.empty:\\n        return \"No match found\"\\n    else:\\n        return final_matches.head(top_k)[\\n            [\\'alias_name\\', \\'DateLst\\', \\'IDLst\\', \\'cos_sim\\', \\'levenshtein\\', \\'dob_match\\', \\'id_match\\', \\'match_prob\\']\\n        ]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def hybrid_name_matcher(input_name, input_dob=None, input_id=None, top_k=5, ml_threshold=0.5):\n",
    "    name_clean = re.sub(r\"[^\\w\\s]\", \"\", input_name.lower()).strip()\n",
    "    query_vec = model.encode([name_clean]).astype('float32')\n",
    "\n",
    "    cos_sims = cosine_similarity(query_vec, embeddings)[0]\n",
    "    best_index = np.argmax(cos_sims)\n",
    "    cluster_id = df.loc[best_index, 'cluster_id']\n",
    "\n",
    "    if cluster_id == -1:\n",
    "        top_indices = np.argsort(cos_sims)[::-1][:top_k*3]\n",
    "        candidates = df.loc[top_indices].copy()\n",
    "        candidate_embeddings = embeddings[top_indices]\n",
    "        candidate_cos_sims = cos_sims[top_indices]\n",
    "    else:\n",
    "        candidates = df[df['cluster_id'] == cluster_id].copy()\n",
    "        candidate_embeddings = embeddings[candidates.index]\n",
    "        candidate_cos_sims = cosine_similarity(query_vec, candidate_embeddings)[0]\n",
    "\n",
    "    candidates = candidates.assign(cos_sim=candidate_cos_sims)\n",
    "    candidates['levenshtein'] = candidates['clean_name'].apply(lambda x: levenshtein_ratio(name_clean, x))\n",
    "    candidates['dob_match'] = candidates['DateLst'].astype(str) == str(input_dob) if input_dob else False\n",
    "    candidates['id_match'] = candidates['IDLst'].astype(str) == str(input_id) if input_id else False\n",
    "\n",
    "    features = candidates[['cos_sim', 'levenshtein', 'dob_match', 'id_match']].astype(float)\n",
    "    candidates['match_prob'] = clf.predict_proba(features)[:, 1]\n",
    "\n",
    "    final_matches = candidates[candidates['match_prob'] >= ml_threshold].sort_values(by='match_prob', ascending=False)\n",
    "\n",
    "    if final_matches.empty:\n",
    "        return \"No match found\"\n",
    "    else:\n",
    "        return final_matches.head(top_k)[\n",
    "            ['alias_name', 'DateLst', 'IDLst', 'cos_sim', 'levenshtein', 'dob_match', 'id_match', 'match_prob']\n",
    "        ]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25680b99-9d09-4762-a145-a68babb7baea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9298eabd-d53f-433f-89fc-10a3e400ab1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hybrid_name_matcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m hybrid_name_matcher(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSinshi\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_dob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1990-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12345\u001b[39m\u001b[38;5;124m\"\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, ml_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hybrid_name_matcher' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92fb0d-3fb4-4783-b410-cda9b3c0a378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
